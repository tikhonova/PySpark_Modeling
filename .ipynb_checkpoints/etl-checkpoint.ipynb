{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3688/2653304689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_columns'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdate_add\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import date_add, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launching a spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing immigration data:\n",
    "* spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "* spark.write.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "c = pd.read_csv(\"/Users/tatianatikhonova/Documents/udacity/Capstone/us-cities-demographics.csv\", sep = ';')\n",
    "a = pd.read_csv(\"/Users/tatianatikhonova/Documents/udacity/Capstone/airport-codes.csv\", sep = ',')\n",
    "immigration = spark.read.parquet(\"sas_data\") \n",
    "\n",
    "#immigration sample\n",
    "i = pd.read_csv(\"/Users/tatianatikhonova/Documents/udacity/Capstone/immigration_data_sample.csv\", sep = ',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data dictionary for Immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')\n",
    "\n",
    "def code_mapper(file, idx):\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    return dic\n",
    "\n",
    "i94cit_res = code_mapper(f_content, \"i94cntyl\")\n",
    "i94port = code_mapper(f_content, \"i94prtl\")\n",
    "i94mode = code_mapper(f_content, \"i94model\")\n",
    "i94addr = code_mapper(f_content, \"i94addrl\")\n",
    "i94visa = {'1':'Business',\n",
    "'2': 'Pleasure',\n",
    "'3' : 'Student'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#turning listo of ports into a dataframe with distinct columns\n",
    "i94port_df = pd.DataFrame.from_dict(i94port, orient='index')\n",
    "i94port_df.reset_index(level=0, inplace=True)\n",
    "i94port_df.columns = ['Code','City_State']\n",
    "i94port_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#splitting City_State column in two\n",
    "i94port_df[['City', 'State','Else']] = i94port_df['City_State'].astype(\"string\").str.split(', ', expand=True)\n",
    "i94port_df.drop(['City_State', 'Else'], axis=1, inplace=True)\n",
    "i94port_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Counting % of missing ports out of total. Turns out to be 9%\n",
    "i94port_df.query('City.str.contains(\"No PORT\")', engine='python').count() / i94port_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_ports_list = list(i94port_df.query('City.str.contains(\"No PORT\")', engine='python').Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "\n",
    "What I will be looking out for:\n",
    "\n",
    "* **Completeness** (do we have all the records that we need? any missing / NaaN?)\n",
    "* **Validity** (records that donâ€™t conform to a defined schema, e.g. negative height not possible but present or duplicate key identifier)\n",
    "* **Accuracy** (adheres to define schema, but is incorrect; e.g. overestimated values or out of date information)\n",
    "* **Consistency** (data valid and accurate, but fields are represented in an inconsistent manner, e.g. state as NY and New York)\n",
    "* **Tidiness** (structure of tidy data: variable = column, observation = row, observational unit = table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "immigration.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#understand number of rows and columns\n",
    "print(f'count of rows and columns for cities: {c.shape}')\n",
    "print(f'count of rows and columns for airports: {a.shape}')\n",
    "print(f'count of rows and columns for immigration: {immigration.count(), len(immigration.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#understand columns and data types\n",
    "c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.columns.to_series().groupby(c.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values in Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_data(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "        df - (dataframe), dataframe to check for missing values in its columns\n",
    "    OUTPUT:\n",
    "        df_null: (dataframe), with count & percentage of missing values in input dataframe columns\n",
    "    '''\n",
    "    null_data = df.isnull().sum()[df.isnull().sum() > 0]\n",
    "    \n",
    "    data_dict = {'count': null_data.values, \n",
    "                 'pct': np.round(null_data.values *100/df.shape[0],2)}\n",
    "    \n",
    "    df_null = pd.DataFrame(data=data_dict, index=null_data.index)\n",
    "    df_null.sort_values(by='count', ascending=False, inplace=True)\n",
    "    return df_null\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.isnull().sum().sum() #count of all missing values in Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_missing_data(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def nans(df): \n",
    "    return df[df.isnull().any(axis=1)]\n",
    "\n",
    "nans(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values comprise less than 1% of Cities data, so it's safe to drop them\n",
    "c2 = c.dropna(axis=0)\n",
    "c2.isnull().sum().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values in Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.isnull().sum().sum() #count of all missing values in Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_missing_data(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropping columns that are missing over 25% of data\n",
    "cols = a.columns[a.isnull().sum()/len(a) > .25]\n",
    "a2 = a.drop(cols,axis=1)\n",
    "a2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the remaining rows with null values\n",
    "a2.dropna(axis=0, inplace=True)\n",
    "a2.isnull().sum().sum() #count of all missing values in Airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values in Immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(immigration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i2 = immigration[~immigration[\"i94port\"].isin(missing_ports_list)] #filtering out missng ports derived from the SAS file\n",
    "\n",
    "{col:i2.filter(i2[col].isNull()).count() / i2.count() for col in i2.columns} #checking % of null values in each col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i2 = i2.drop(\"insnum\", \"entdepu\", \"occup\", \"visapost\") #dropping extra columns\n",
    "i2 = i2.dropna(how='any') #dropping null values\n",
    "{col:i2.filter(i2[col].isNull()).count() / i2.count() for col in i2.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2 = i2.filter(i2.i94addr != 'other')\n",
    "i3 = i2.select(col(\"cicid\").alias(\"id\"), \n",
    "                                       col(\"arrdate\").alias(\"arrival_date\"),\n",
    "                                       col(\"i94port\").alias(\"port_code\"),\n",
    "                                       col(\"i94addr\").alias(\"state_code\"),\n",
    "                                       col(\"i94bir\").alias(\"age\"),\n",
    "                                       col(\"gender\").alias(\"gender\"),\n",
    "                                       col(\"i94visa\").alias(\"visa_type\"),\n",
    "                                       \"count\").drop_duplicates()\n",
    "\n",
    "i3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type(i3.arrival_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i3 = i3.withColumn('new_arr_date', col(\"arrival_date\").cast(\"timestamp\"))\n",
    "i3 = i3.drop('arrival_date')\n",
    "i3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immigration = FACT\n",
    "Airports = DIM\n",
    "Cities = DIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pyspark --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i3.write.mode(\"append\").partitionBy(\"port_code\").parquet(\"/results/immigration.parquet\")\\\n",
    "        .mode('overwrite')\\\n",
    "        .trigger(processingTime=\"20 seconds\") \\\n",
    "        .outputMode('Complete') \\\n",
    "        .format('console') \\\n",
    "        .start()\\\n",
    "        .awaitTermination()\n",
    "# writing immigration dimension table to parquet files partitioned by port_code\n",
    "#i3.createOrReplaceTempView(\"immigration_view\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immigration columns:\n",
    "\n",
    "*  cicid      primary key, id from sas file\n",
    "*  i94yr      entry year, 4 digit year\n",
    "*  i94mon     entry month, numeric month\n",
    "*  i94cit     i94 citizenship country code as per SAS Labels Descriptions file\n",
    "*   i94res    i94 residence country code as per SAS Labels Descriptions file\n",
    "*  i94port     i94port code as per SAS Labels Descriptions file\n",
    "*  arrdate     date of arrival in U.S.\n",
    "*  i94mode     code for travel mode of arrival as per SAS Labels Descriptions file\n",
    "*  i94addr     address\n",
    "*  depdate     departure date from U.S.\n",
    "*  i94bir      age of the immigrant\n",
    "*  i94visa     visa category code as per SAS Labels Descriptions file\n",
    "*  dtadfile    Character Date Field - Date added to I-94 Files - CIC does not use */  \n",
    "*  visapost    visa category code as per SAS Labels Descriptions file\n",
    "*  occup       occupation of immigrant\n",
    "*  entdepa     Arrival Flag - admitted or paroled into the U.S. - CIC does not use\n",
    "*  entdepd     Departure Flag - Departed, lost I-94 or is deceased - CIC does not use\n",
    "*  entdepu     Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use\n",
    "*  matflag     Match flag - Match of arrival and departure records\n",
    "*  biryear     birth year of immigrant\n",
    "* count        used for summary stats\n",
    "*  dtaddto     character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use */\n",
    "*  gender      gender of immigrant\n",
    "*  insnum      INS number\n",
    "*  airline     airline code used to arrive in U.S.\n",
    "*  admnum      admission number\n",
    "*  fltno       flight number\n",
    "*  visatype  visa type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-77-33effe78f7ae>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-77-33effe78f7ae>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    fact_immigraions:\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "fact_immigraions:\n",
    "|-- cicid: id from sas file\n",
    "|-- entry_year: 4 digit year\n",
    "|-- entry_month: numeric month\n",
    "|-- origin_country_code: i94 country code as per SAS Labels Descriptions file\n",
    "|-- port_code: i94port code as per SAS Labels Descriptions file\n",
    "|-- arrival_date: date of arrival in U.S.\n",
    "|-- travel_mode_code: code for travel mode of arrival as per SAS Labels Descriptions file\n",
    "|-- us_state_code: two letter U.S. state code\n",
    "|-- departure_date: departure date from U.S.\n",
    "|-- age: age of the immigrant\n",
    "|-- visa_category_code: visa category code as per SAS Labels Descriptions file\n",
    "|-- occupation: occupation of immigrant\n",
    "|-- gender: gender of immigrant\n",
    "|-- birth_year: birth year of immigrant\n",
    "|-- entry_date: Date to which admitted to U.S. (allowed to stay until)\n",
    "|-- airline: airline code used to arrive in U.S.\n",
    "|-- admission_number: admission number\n",
    "|-- flight_number: flight number\n",
    "|-- visa_type: visa type\n",
    "    \n",
    "dim_city_demographics:\n",
    "|-- port_code: i94port code\n",
    "|-- city: U.S. city name\n",
    "|-- state_code: two letter U.S. sate code\n",
    "|-- male_population: total male population\n",
    "|-- female_population: total female population\n",
    "|-- total_population: total population\n",
    "|-- number_of_veterans: number of veterans\n",
    "|-- num_foreign_born: number of foreign born "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
