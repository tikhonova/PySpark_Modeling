{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launching a spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing immigration data:\n",
    "* spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "* spark.write.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "c = pd.read_csv(\"/Users/tatianatikhonova/Documents/udacity/Capstone/us-cities-demographics.csv\", sep = ';')\n",
    "a = pd.read_csv(\"/Users/tatianatikhonova/Documents/udacity/Capstone/airport-codes.csv\", sep = ',')\n",
    "immigration = spark.read.parquet(\"sas_data\") \n",
    "\n",
    "#immigration sample\n",
    "i = pd.read_csv(\"/Users/tatianatikhonova/Documents/udacity/Capstone/immigration_data_sample.csv\", sep = ',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data dictionary for Immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')\n",
    "\n",
    "def code_mapper(file, idx):\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    return dic\n",
    "\n",
    "i94cit_res = code_mapper(f_content, \"i94cntyl\")\n",
    "i94port = code_mapper(f_content, \"i94prtl\")\n",
    "i94mode = code_mapper(f_content, \"i94model\")\n",
    "i94addr = code_mapper(f_content, \"i94addrl\")\n",
    "i94visa = {'1':'Business',\n",
    "'2': 'Pleasure',\n",
    "'3' : 'Student'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>City_State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>ADU</td>\n",
       "      <td>No PORT Code (ADU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>AKT</td>\n",
       "      <td>No PORT Code (AKT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>LIT</td>\n",
       "      <td>No PORT Code (LIT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>A2A</td>\n",
       "      <td>No PORT Code (A2A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>OSN</td>\n",
       "      <td>No PORT Code (OSN)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code                    City_State\n",
       "0    ALC                     ALCAN, AK\n",
       "1    ANC                 ANCHORAGE, AK\n",
       "2    BAR  BAKER AAF - BAKER ISLAND, AK\n",
       "3    DAC             DALTONS CACHE, AK\n",
       "4    PIZ    DEW STATION PT LAY DEW, AK\n",
       "..   ...                           ...\n",
       "655  ADU            No PORT Code (ADU)\n",
       "656  AKT            No PORT Code (AKT)\n",
       "657  LIT            No PORT Code (LIT)\n",
       "658  A2A            No PORT Code (A2A)\n",
       "659  OSN            No PORT Code (OSN)\n",
       "\n",
       "[660 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turning listo of ports into a dataframe with distinct columns\n",
    "i94port_df = pd.DataFrame.from_dict(i94port, orient='index')\n",
    "i94port_df.reset_index(level=0, inplace=True)\n",
    "i94port_df.columns = ['Code','City_State']\n",
    "i94port_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>ADU</td>\n",
       "      <td>No PORT Code (ADU)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>AKT</td>\n",
       "      <td>No PORT Code (AKT)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>LIT</td>\n",
       "      <td>No PORT Code (LIT)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>A2A</td>\n",
       "      <td>No PORT Code (A2A)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>OSN</td>\n",
       "      <td>No PORT Code (OSN)</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code                      City State\n",
       "0    ALC                     ALCAN    AK\n",
       "1    ANC                 ANCHORAGE    AK\n",
       "2    BAR  BAKER AAF - BAKER ISLAND    AK\n",
       "3    DAC             DALTONS CACHE    AK\n",
       "4    PIZ    DEW STATION PT LAY DEW    AK\n",
       "..   ...                       ...   ...\n",
       "655  ADU        No PORT Code (ADU)  <NA>\n",
       "656  AKT        No PORT Code (AKT)  <NA>\n",
       "657  LIT        No PORT Code (LIT)  <NA>\n",
       "658  A2A        No PORT Code (A2A)  <NA>\n",
       "659  OSN        No PORT Code (OSN)  <NA>\n",
       "\n",
       "[660 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting City_State column in two\n",
    "i94port_df[['City', 'State','Else']] = i94port_df['City_State'].astype(\"string\").str.split(', ', expand=True)\n",
    "i94port_df.drop(['City_State', 'Else'], axis=1, inplace=True)\n",
    "i94port_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code     0.090909\n",
       "City     0.090909\n",
       "State    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting % of missing ports out of total. Turns out to be 9%\n",
    "i94port_df.query('City.str.contains(\"No PORT\")', engine='python').count() / i94port_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_ports_list = list(i94port_df.query('City.str.contains(\"No PORT\")', engine='python').Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "\n",
    "What I will be looking out for:\n",
    "\n",
    "* **Completeness** (do we have all the records that we need? any missing / NaaN?)\n",
    "* **Validity** (records that don’t conform to a defined schema, e.g. negative height not possible but present or duplicate key identifier)\n",
    "* **Accuracy** (adheres to define schema, but is incorrect; e.g. overestimated values or out of date information)\n",
    "* **Consistency** (data valid and accurate, but fields are represented in an inconsistent manner, e.g. state as NY and New York)\n",
    "* **Tidiness** (structure of tidy data: variable = column, observation = row, observational unit = table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wichita</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>34.6</td>\n",
       "      <td>192354.0</td>\n",
       "      <td>197601.0</td>\n",
       "      <td>389955</td>\n",
       "      <td>23978.0</td>\n",
       "      <td>40270.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>KS</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allen</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>33.5</td>\n",
       "      <td>60626.0</td>\n",
       "      <td>59581.0</td>\n",
       "      <td>120207</td>\n",
       "      <td>5691.0</td>\n",
       "      <td>19652.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>PA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>22304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Danbury</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>37.3</td>\n",
       "      <td>43435.0</td>\n",
       "      <td>41227.0</td>\n",
       "      <td>84662</td>\n",
       "      <td>3752.0</td>\n",
       "      <td>25675.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>CT</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>8454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nashville</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>34.1</td>\n",
       "      <td>314231.0</td>\n",
       "      <td>340365.0</td>\n",
       "      <td>654596</td>\n",
       "      <td>27942.0</td>\n",
       "      <td>88193.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>TN</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>67526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stamford</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>35.4</td>\n",
       "      <td>64941.0</td>\n",
       "      <td>63936.0</td>\n",
       "      <td>128877</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>44003.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>CT</td>\n",
       "      <td>Asian</td>\n",
       "      <td>11013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City         State  Median Age  Male Population  Female Population  Total Population  Number of Veterans  Foreign-born  Average Household Size State Code                               Race  Count\n",
       "0    Wichita        Kansas        34.6         192354.0           197601.0            389955             23978.0       40270.0                    2.56         KS  American Indian and Alaska Native   8791\n",
       "1      Allen  Pennsylvania        33.5          60626.0            59581.0            120207              5691.0       19652.0                    2.67         PA          Black or African-American  22304\n",
       "2    Danbury   Connecticut        37.3          43435.0            41227.0             84662              3752.0       25675.0                    2.74         CT          Black or African-American   8454\n",
       "3  Nashville     Tennessee        34.1         314231.0           340365.0            654596             27942.0       88193.0                    2.39         TN                 Hispanic or Latino  67526\n",
       "4   Stamford   Connecticut        35.4          64941.0            63936.0            128877              2269.0       44003.0                    2.70         CT                              Asian  11013"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft continent iso_country iso_region  municipality gps_code iata_code local_code                            coordinates\n",
       "0   00A       heliport                   Total Rf Heliport          11.0       NaN          US      US-PA      Bensalem      00A       NaN        00A     -74.93360137939453, 40.07080078125\n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0       NaN          US      US-KS         Leoti     00AA       NaN       00AA                 -101.473911, 38.704022\n",
       "2  00AK  small_airport                        Lowell Field         450.0       NaN          US      US-AK  Anchor Point     00AK       NaN       00AK            -151.695999146, 59.94919968\n",
       "3  00AL  small_airport                        Epps Airpark         820.0       NaN          US      US-AL       Harvest     00AL       NaN       00AL  -86.77030181884766, 34.86479949951172\n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0       NaN          US      US-AR       Newport      NaN       NaN        NaN                    -91.254898, 35.6087"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline        admnum  fltno visatype\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0      1.0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN       G       O      NaN       M   1955.0  07202016      F     NaN      JL  5.658267e+10  00782       WT\n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0      1.0      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN       G       R      NaN       M   1990.0  10222016      M     NaN     *GA  9.436200e+10  XBLNG       B2\n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0      1.0      FL  20571.0    76.0      2.0    1.0  20160407      NaN   NaN       G       O      NaN       M   1940.0  07052016      M     NaN      LH  5.578047e+10  00464       WT\n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0      1.0      CA  20581.0    25.0      2.0    1.0  20160428      DOH   NaN       G       O      NaN       M   1991.0  10272016      M     NaN      QR  9.478970e+10  00739       B2\n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0      3.0      NY  20553.0    19.0      2.0    1.0  20160406      NaN   NaN       Z       K      NaN       M   1997.0  07042016      F     NaN     NaN  4.232257e+10   LAND       WT"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALC': 'ALCAN, AK',\n",
       " 'ANC': 'ANCHORAGE, AK',\n",
       " 'BAR': 'BAKER AAF - BAKER ISLAND, AK',\n",
       " 'DAC': 'DALTONS CACHE, AK',\n",
       " 'PIZ': 'DEW STATION PT LAY DEW, AK',\n",
       " 'DTH': 'DUTCH HARBOR, AK',\n",
       " 'EGL': 'EAGLE, AK',\n",
       " 'FRB': 'FAIRBANKS, AK',\n",
       " 'HOM': 'HOMER, AK',\n",
       " 'HYD': 'HYDER, AK',\n",
       " 'JUN': 'JUNEAU, AK',\n",
       " '5KE': 'KETCHIKAN, AK',\n",
       " 'KET': 'KETCHIKAN, AK',\n",
       " 'MOS': 'MOSES POINT INTERMEDIATE, AK',\n",
       " 'NIK': 'NIKISKI, AK',\n",
       " 'NOM': 'NOM, AK',\n",
       " 'PKC': 'POKER CREEK, AK',\n",
       " 'ORI': 'PORT LIONS SPB, AK',\n",
       " 'SKA': 'SKAGWAY, AK',\n",
       " 'SNP': 'ST. PAUL ISLAND, AK',\n",
       " 'TKI': 'TOKEEN, AK',\n",
       " 'WRA': 'WRANGELL, AK',\n",
       " 'HSV': 'MADISON COUNTY - HUNTSVILLE, AL',\n",
       " 'MOB': 'MOBILE, AL',\n",
       " 'LIA': 'LITTLE ROCK, AR (BPS)',\n",
       " 'ROG': 'ROGERS ARPT, AR',\n",
       " 'DOU': 'DOUGLAS, AZ',\n",
       " 'LUK': 'LUKEVILLE, AZ',\n",
       " 'MAP': 'MARIPOSA AZ',\n",
       " 'NAC': 'NACO, AZ',\n",
       " 'NOG': 'NOGALES, AZ',\n",
       " 'PHO': 'PHOENIX, AZ',\n",
       " 'POR': 'PORTAL, AZ',\n",
       " 'SLU': 'SAN LUIS, AZ',\n",
       " 'SAS': 'SASABE, AZ',\n",
       " 'TUC': 'TUCSON, AZ',\n",
       " 'YUI': 'YUMA, AZ',\n",
       " 'AND': 'ANDRADE, CA',\n",
       " 'BUR': 'BURBANK, CA',\n",
       " 'CAL': 'CALEXICO, CA',\n",
       " 'CAO': 'CAMPO, CA',\n",
       " 'FRE': 'FRESNO, CA',\n",
       " 'ICP': 'IMPERIAL COUNTY, CA',\n",
       " 'LNB': 'LONG BEACH, CA',\n",
       " 'LOS': 'LOS ANGELES, CA',\n",
       " 'BFL': 'MEADOWS FIELD - BAKERSFIELD, CA',\n",
       " 'OAK': 'OAKLAND, CA',\n",
       " 'ONT': 'ONTARIO, CA',\n",
       " 'OTM': 'OTAY MESA, CA',\n",
       " 'BLT': 'PACIFIC, HWY. STATION, CA',\n",
       " 'PSP': 'PALM SPRINGS, CA',\n",
       " 'SAC': 'SACRAMENTO, CA',\n",
       " 'SLS': 'SALINAS, CA (BPS)',\n",
       " 'SDP': 'SAN DIEGO, CA',\n",
       " 'SFR': 'SAN FRANCISCO, CA',\n",
       " 'SNJ': 'SAN JOSE, CA',\n",
       " 'SLO': 'SAN LUIS OBISPO, CA',\n",
       " 'SLI': 'SAN LUIS OBISPO, CA (BPS)',\n",
       " 'SPC': 'SAN PEDRO, CA',\n",
       " 'SYS': 'SAN YSIDRO, CA',\n",
       " 'SAA': 'SANTA ANA, CA',\n",
       " 'STO': 'STOCKTON, CA (BPS)',\n",
       " 'TEC': 'TECATE, CA',\n",
       " 'TRV': 'TRAVIS-AFB, CA',\n",
       " 'APA': 'ARAPAHOE COUNTY, CO',\n",
       " 'ASE': 'ASPEN, CO #ARPT',\n",
       " 'COS': 'COLORADO SPRINGS, CO',\n",
       " 'DEN': 'DENVER, CO',\n",
       " 'DRO': 'LA PLATA - DURANGO, CO',\n",
       " 'BDL': 'BRADLEY INTERNATIONAL, CT',\n",
       " 'BGC': 'BRIDGEPORT, CT',\n",
       " 'GRT': 'GROTON, CT',\n",
       " 'HAR': 'HARTFORD, CT',\n",
       " 'NWH': 'NEW HAVEN, CT',\n",
       " 'NWL': 'NEW LONDON, CT',\n",
       " 'TST': 'NEWINGTON DATA CENTER TEST, CT',\n",
       " 'WAS': 'WASHINGTON DC',\n",
       " 'DOV': 'DOVER AFB, DE',\n",
       " 'DVD': 'DOVER-AFB, DE',\n",
       " 'WLL': 'WILMINGTON, DE',\n",
       " 'BOC': 'BOCAGRANDE, FL',\n",
       " 'SRQ': 'BRADENTON - SARASOTA, FL',\n",
       " 'CAN': 'CAPE CANAVERAL, FL',\n",
       " 'DAB': 'DAYTONA BEACH INTERNATIONAL, FL',\n",
       " 'FRN': 'FERNANDINA, FL',\n",
       " 'FTL': 'FORT LAUDERDALE, FL',\n",
       " 'FMY': 'FORT MYERS, FL',\n",
       " 'FPF': 'FORT PIERCE, FL',\n",
       " 'HUR': 'HURLBURT FIELD, FL',\n",
       " 'GNV': 'J R ALISON MUNI - GAINESVILLE, FL',\n",
       " 'JAC': 'JACKSONVILLE, FL',\n",
       " 'KEY': 'KEY WEST, FL',\n",
       " 'LEE': 'LEESBURG MUNICIPAL AIRPORT, FL',\n",
       " 'MLB': 'MELBOURNE, FL',\n",
       " 'MIA': 'MIAMI, FL',\n",
       " 'APF': 'NAPLES, FL #ARPT',\n",
       " 'OPF': 'OPA LOCKA, FL',\n",
       " 'ORL': 'ORLANDO, FL',\n",
       " 'PAN': 'PANAMA CITY, FL',\n",
       " 'PEN': 'PENSACOLA, FL',\n",
       " 'PCF': 'PORT CANAVERAL, FL',\n",
       " 'PEV': 'PORT EVERGLADES, FL',\n",
       " 'PSJ': 'PORT ST JOE, FL',\n",
       " 'SFB': 'SANFORD, FL',\n",
       " 'SGJ': 'ST AUGUSTINE ARPT, FL',\n",
       " 'SAU': 'ST AUGUSTINE, FL',\n",
       " 'FPR': 'ST LUCIE COUNTY, FL',\n",
       " 'SPE': 'ST PETERSBURG, FL',\n",
       " 'TAM': 'TAMPA, FL',\n",
       " 'WPB': 'WEST PALM BEACH, FL',\n",
       " 'ATL': 'ATLANTA, GA',\n",
       " 'BRU': 'BRUNSWICK, GA',\n",
       " 'AGS': 'BUSH FIELD - AUGUSTA, GA',\n",
       " 'SAV': 'SAVANNAH, GA',\n",
       " 'AGA': 'AGANA, GU',\n",
       " 'HHW': 'HONOLULU, HI',\n",
       " 'OGG': 'KAHULUI - MAUI, HI',\n",
       " 'KOA': 'KEAHOLE-KONA, HI',\n",
       " 'LIH': 'LIHUE, HI',\n",
       " 'CID': 'CEDAR RAPIDS/IOWA CITY, IA',\n",
       " 'DSM': 'DES MOINES, IA',\n",
       " 'BOI': 'AIR TERM. (GOWEN FLD) BOISE, ID',\n",
       " 'EPI': 'EASTPORT, ID',\n",
       " 'IDA': 'FANNING FIELD - IDAHO FALLS, ID',\n",
       " 'PTL': 'PORTHILL, ID',\n",
       " 'SPI': 'CAPITAL - SPRINGFIELD, IL',\n",
       " 'CHI': 'CHICAGO, IL',\n",
       " 'DPA': 'DUPAGE COUNTY, IL',\n",
       " 'PIA': 'GREATER PEORIA, IL',\n",
       " 'RFD': 'GREATER ROCKFORD, IL',\n",
       " 'UGN': 'MEMORIAL - WAUKEGAN, IL',\n",
       " 'GAR': 'GARY, IN',\n",
       " 'HMM': 'HAMMOND, IN',\n",
       " 'INP': 'INDIANAPOLIS, IN',\n",
       " 'MRL': 'MERRILLVILLE, IN',\n",
       " 'SBN': 'SOUTH BEND, IN',\n",
       " 'ICT': 'MID-CONTINENT - WITCHITA, KS',\n",
       " 'LEX': 'BLUE GRASS - LEXINGTON, KY',\n",
       " 'LOU': 'LOUISVILLE, KY',\n",
       " 'BTN': 'BATON ROUGE, LA',\n",
       " 'LKC': 'LAKE CHARLES, LA',\n",
       " 'LAK': 'LAKE CHARLES, LA (BPS)',\n",
       " 'MLU': 'MONROE, LA',\n",
       " 'MGC': 'MORGAN CITY, LA',\n",
       " 'NOL': 'NEW ORLEANS, LA',\n",
       " 'BOS': 'BOSTON, MA',\n",
       " 'GLO': 'GLOUCESTER, MA',\n",
       " 'BED': 'HANSCOM FIELD - BEDFORD, MA',\n",
       " 'LYN': 'LYNDEN, WA',\n",
       " 'ADW': 'ANDREWS AFB, MD',\n",
       " 'BAL': 'BALTIMORE, MD',\n",
       " 'MKG': 'MUSKEGON, MD',\n",
       " 'PAX': 'PATUXENT RIVER, MD',\n",
       " 'BGM': 'BANGOR, ME',\n",
       " 'BOO': 'BOOTHBAY HARBOR, ME',\n",
       " 'BWM': 'BRIDGEWATER, ME',\n",
       " 'BCK': 'BUCKPORT, ME',\n",
       " 'CLS': 'CALAIS, ME',\n",
       " 'CRB': 'CARIBOU, ME',\n",
       " 'COB': 'COBURN GORE, ME',\n",
       " 'EST': 'EASTCOURT, ME',\n",
       " 'EPT': 'EASTPORT MUNICIPAL, ME',\n",
       " 'EPM': 'EASTPORT, ME',\n",
       " 'FOR': 'FOREST CITY, ME',\n",
       " 'FTF': 'FORT FAIRFIELD, ME',\n",
       " 'FTK': 'FORT KENT, ME',\n",
       " 'HML': 'HAMIIN, ME',\n",
       " 'HTM': 'HOULTON, ME',\n",
       " 'JKM': 'JACKMAN, ME',\n",
       " 'KAL': 'KALISPEL, MT',\n",
       " 'LIM': 'LIMESTONE, ME',\n",
       " 'LUB': 'LUBEC, ME',\n",
       " 'MAD': 'MADAWASKA, ME',\n",
       " 'POM': 'PORTLAND, ME',\n",
       " 'RGM': 'RANGELEY, ME (BPS)',\n",
       " 'SBR': 'SOUTH BREWER, ME',\n",
       " 'SRL': 'ST AURELIE, ME',\n",
       " 'SPA': 'ST PAMPILE, ME',\n",
       " 'VNB': 'VAN BUREN, ME',\n",
       " 'VCB': 'VANCEBORO, ME',\n",
       " 'AGN': 'ALGONAC, MI',\n",
       " 'ALP': 'ALPENA, MI',\n",
       " 'BCY': 'BAY CITY, MI',\n",
       " 'DET': 'DETROIT, MI',\n",
       " 'GRP': 'GRAND RAPIDS, MI',\n",
       " 'GRO': 'GROSSE ISLE, MI',\n",
       " 'ISL': 'ISLE ROYALE, MI',\n",
       " 'MRC': 'MARINE CITY, MI',\n",
       " 'MRY': 'MARYSVILLE, MI',\n",
       " 'PTK': 'OAKLAND COUNTY - PONTIAC, MI',\n",
       " 'PHU': 'PORT HURON, MI',\n",
       " 'RBT': 'ROBERTS LANDING, MI',\n",
       " 'SAG': 'SAGINAW, MI',\n",
       " 'SSM': 'SAULT STE. MARIE, MI',\n",
       " 'SCL': 'ST CLAIR, MI',\n",
       " 'YIP': 'WILLOW RUN - YPSILANTI, MI',\n",
       " 'BAU': 'BAUDETTE, MN',\n",
       " 'CAR': 'CARIBOU MUNICIPAL AIRPORT, MN',\n",
       " 'GTF': 'Collapsed into INT, MN',\n",
       " 'INL': 'Collapsed into INT, MN',\n",
       " 'CRA': 'CRANE LAKE, MN',\n",
       " 'MIC': 'CRYSTAL MUNICIPAL AIRPORT, MN',\n",
       " 'DUL': 'DULUTH, MN',\n",
       " 'ELY': 'ELY, MN',\n",
       " 'GPM': 'GRAND PORTAGE, MN',\n",
       " 'SVC': 'GRANT COUNTY - SILVER CITY, MN',\n",
       " 'INT': 'INTL FALLS, MN',\n",
       " 'LAN': 'LANCASTER, MN',\n",
       " 'MSP': 'MINN./ST PAUL, MN',\n",
       " 'LIN': 'NORTHERN SVC CENTER, MN',\n",
       " 'NOY': 'NOYES, MN',\n",
       " 'PIN': 'PINE CREEK, MN',\n",
       " '48Y': 'PINECREEK BORDER ARPT, MN',\n",
       " 'RAN': 'RAINER, MN',\n",
       " 'RST': 'ROCHESTER, MN',\n",
       " 'ROS': 'ROSEAU, MN',\n",
       " 'SPM': 'ST PAUL, MN',\n",
       " 'WSB': 'WARROAD INTL, SPB, MN',\n",
       " 'WAR': 'WARROAD, MN',\n",
       " 'KAN': 'KANSAS CITY, MO',\n",
       " 'SGF': 'SPRINGFIELD-BRANSON, MO',\n",
       " 'STL': 'ST LOUIS, MO',\n",
       " 'WHI': 'WHITETAIL, MT',\n",
       " 'WHM': 'WILD HORSE, MT',\n",
       " 'GPT': 'BILOXI REGIONAL, MS',\n",
       " 'GTR': 'GOLDEN TRIANGLE LOWNDES CNTY, MS',\n",
       " 'GUL': 'GULFPORT, MS',\n",
       " 'PAS': 'PASCAGOULA, MS',\n",
       " 'JAN': 'THOMPSON FIELD - JACKSON, MS',\n",
       " 'BIL': 'BILLINGS, MT',\n",
       " 'BTM': 'BUTTE, MT',\n",
       " 'CHF': 'CHIEF MT, MT',\n",
       " 'CTB': 'CUT BANK MUNICIPAL, MT',\n",
       " 'CUT': 'CUT BANK, MT',\n",
       " 'DLB': 'DEL BONITA, MT',\n",
       " 'EUR': 'EUREKA, MT (BPS)',\n",
       " 'BZN': 'GALLATIN FIELD - BOZEMAN, MT',\n",
       " 'FCA': 'GLACIER NATIONAL PARK, MT',\n",
       " 'GGW': 'GLASGOW, MT',\n",
       " 'GRE': 'GREAT FALLS, MT',\n",
       " 'HVR': 'HAVRE, MT',\n",
       " 'HEL': 'HELENA, MT',\n",
       " 'LWT': 'LEWISTON, MT',\n",
       " 'MGM': 'MORGAN, MT',\n",
       " 'OPH': 'OPHEIM, MT',\n",
       " 'PIE': 'PIEGAN, MT',\n",
       " 'RAY': 'RAYMOND, MT',\n",
       " 'ROO': 'ROOSVILLE, MT',\n",
       " 'SCO': 'SCOBEY, MT',\n",
       " 'SWE': 'SWEETGTASS, MT',\n",
       " 'TRL': 'TRIAL CREEK, MT',\n",
       " 'TUR': 'TURNER, MT',\n",
       " 'WCM': 'WILLOW CREEK, MT',\n",
       " 'CLT': 'CHARLOTTE, NC',\n",
       " 'FAY': 'FAYETTEVILLE, NC',\n",
       " 'MRH': 'MOREHEAD CITY, NC',\n",
       " 'FOP': 'MORRIS FIELDS AAF, NC',\n",
       " 'GSO': 'PIEDMONT TRIAD INTL AIRPORT, NC',\n",
       " 'RDU': 'RALEIGH/DURHAM, NC',\n",
       " 'SSC': 'SHAW AFB - SUMTER, NC',\n",
       " 'WIL': 'WILMINGTON, NC',\n",
       " 'AMB': 'AMBROSE, ND',\n",
       " 'ANT': 'ANTLER, ND',\n",
       " 'CRY': 'CARBURY, ND',\n",
       " 'DNS': 'DUNSEITH, ND',\n",
       " 'FAR': 'FARGO, ND',\n",
       " 'FRT': 'FORTUNA, ND',\n",
       " 'GRF': 'GRAND FORKS, ND',\n",
       " 'HNN': 'HANNAH, ND',\n",
       " 'HNS': 'HANSBORO, ND',\n",
       " 'MAI': 'MAIDA, ND',\n",
       " 'MND': 'MINOT, ND',\n",
       " 'NEC': 'NECHE, ND',\n",
       " 'NOO': 'NOONAN, ND',\n",
       " 'NRG': 'NORTHGATE, ND',\n",
       " 'PEM': 'PEMBINA, ND',\n",
       " 'SAR': 'SARLES, ND',\n",
       " 'SHR': 'SHERWOOD, ND',\n",
       " 'SJO': 'ST JOHN, ND',\n",
       " 'WAL': 'WALHALLA, ND',\n",
       " 'WHO': 'WESTHOPE, ND',\n",
       " 'WND': 'WILLISTON, ND',\n",
       " 'OMA': 'OMAHA, NE',\n",
       " 'LEB': 'LEBANON, NH',\n",
       " 'MHT': 'MANCHESTER, NH',\n",
       " 'PNH': 'PITTSBURG, NH',\n",
       " 'PSM': 'PORTSMOUTH, NH',\n",
       " 'BYO': 'BAYONNE, NJ',\n",
       " 'CNJ': 'CAMDEN, NJ',\n",
       " 'HOB': 'HOBOKEN, NJ',\n",
       " 'JER': 'JERSEY CITY, NJ',\n",
       " 'WRI': 'MC GUIRE AFB - WRIGHTSOWN, NJ',\n",
       " 'MMU': 'MORRISTOWN, NJ',\n",
       " 'NEW': 'NEWARK/TETERBORO, NJ',\n",
       " 'PER': 'PERTH AMBOY, NJ',\n",
       " 'ACY': 'POMONA FIELD - ATLANTIC CITY, NJ',\n",
       " 'ALA': 'ALAMAGORDO, NM (BPS)',\n",
       " 'ABQ': 'ALBUQUERQUE, NM',\n",
       " 'ANP': 'ANTELOPE WELLS, NM',\n",
       " 'CRL': 'CARLSBAD, NM',\n",
       " 'COL': 'COLUMBUS, NM',\n",
       " 'CDD': 'CRANE LAKE - ST. LOUIS CNTY, NM',\n",
       " 'DNM': 'DEMING, NM (BPS)',\n",
       " 'LAS': 'LAS CRUCES, NM',\n",
       " 'LOB': 'LORDSBURG, NM (BPS)',\n",
       " 'RUI': 'RUIDOSO, NM',\n",
       " 'STR': 'SANTA TERESA, NM',\n",
       " 'RNO': 'CANNON INTL - RENO/TAHOE, NV',\n",
       " 'FLX': 'FALLON MUNICIPAL AIRPORT, NV',\n",
       " 'LVG': 'LAS VEGAS, NV',\n",
       " 'REN': 'RENO, NV',\n",
       " 'ALB': 'ALBANY, NY',\n",
       " 'AXB': 'ALEXANDRIA BAY, NY',\n",
       " 'BUF': 'BUFFALO, NY',\n",
       " 'CNH': 'CANNON CORNERS, NY',\n",
       " 'CAP': 'CAPE VINCENT, NY',\n",
       " 'CHM': 'CHAMPLAIN, NY',\n",
       " 'CHT': 'CHATEAUGAY, NY',\n",
       " 'CLA': 'CLAYTON, NY',\n",
       " 'FTC': 'FORT COVINGTON, NY',\n",
       " 'LAG': 'LA GUARDIA, NY',\n",
       " 'LEW': 'LEWISTON, NY',\n",
       " 'MAS': 'MASSENA, NY',\n",
       " 'MAG': 'MCGUIRE AFB, NY',\n",
       " 'MOO': 'MOORES, NY',\n",
       " 'MRR': 'MORRISTOWN, NY',\n",
       " 'NYC': 'NEW YORK, NY',\n",
       " 'NIA': 'NIAGARA FALLS, NY',\n",
       " 'OGD': 'OGDENSBURG, NY',\n",
       " 'OSW': 'OSWEGO, NY',\n",
       " 'ELM': 'REGIONAL ARPT - HORSEHEAD, NY',\n",
       " 'ROC': 'ROCHESTER, NY',\n",
       " 'ROU': 'ROUSES POINT, NY',\n",
       " 'SWF': 'STEWART - ORANGE CNTY, NY',\n",
       " 'SYR': 'SYRACUSE, NY',\n",
       " 'THO': 'THOUSAND ISLAND BRIDGE, NY',\n",
       " 'TRO': 'TROUT RIVER, NY',\n",
       " 'WAT': 'WATERTOWN, NY',\n",
       " 'HPN': 'WESTCHESTER - WHITE PLAINS, NY',\n",
       " 'WRB': 'WHIRLPOOL BRIDGE, NY',\n",
       " 'YOU': 'YOUNGSTOWN, NY',\n",
       " 'AKR': 'AKRON, OH',\n",
       " 'ATB': 'ASHTABULA, OH',\n",
       " 'CIN': 'CINCINNATI, OH',\n",
       " 'CLE': 'CLEVELAND, OH',\n",
       " 'CLM': 'COLUMBUS, OH',\n",
       " 'LOR': 'LORAIN, OH',\n",
       " 'MBO': 'MARBLE HEADS, OH',\n",
       " 'SDY': 'SANDUSKY, OH',\n",
       " 'TOL': 'TOLEDO, OH',\n",
       " 'OKC': 'OKLAHOMA CITY, OK',\n",
       " 'TUL': 'TULSA, OK',\n",
       " 'AST': 'ASTORIA, OR',\n",
       " 'COO': 'COOS BAY, OR',\n",
       " 'HIO': 'HILLSBORO, OR',\n",
       " 'MED': 'MEDFORD, OR',\n",
       " 'NPT': 'NEWPORT, OR',\n",
       " 'POO': 'PORTLAND, OR',\n",
       " 'PUT': 'PUT-IN-BAY, OH',\n",
       " 'RDM': 'ROBERTS FIELDS - REDMOND, OR',\n",
       " 'ERI': 'ERIE, PA',\n",
       " 'MDT': 'HARRISBURG, PA',\n",
       " 'HSB': 'HARRISONBURG, PA',\n",
       " 'PHI': 'PHILADELPHIA, PA',\n",
       " 'PIT': 'PITTSBURG, PA',\n",
       " 'AGU': 'AGUADILLA, PR',\n",
       " 'BQN': 'BORINQUEN - AGUADILLO, PR',\n",
       " 'JCP': 'CULEBRA - BENJAMIN RIVERA, PR',\n",
       " 'ENS': 'ENSENADA, PR',\n",
       " 'FAJ': 'FAJARDO, PR',\n",
       " 'HUM': 'HUMACAO, PR',\n",
       " 'JOB': 'JOBOS, PR',\n",
       " 'MAY': 'MAYAGUEZ, PR',\n",
       " 'PON': 'PONCE, PR',\n",
       " 'PSE': 'PONCE-MERCEDITA, PR',\n",
       " 'SAJ': 'SAN JUAN, PR',\n",
       " 'VQS': 'VIEQUES-ARPT, PR',\n",
       " 'PRO': 'PROVIDENCE, RI',\n",
       " 'PVD': 'THEODORE FRANCIS - WARWICK, RI',\n",
       " 'CHL': 'CHARLESTON, SC',\n",
       " 'CAE': 'COLUMBIA, SC #ARPT',\n",
       " 'GEO': 'GEORGETOWN, SC',\n",
       " 'GSP': 'GREENVILLE, SC',\n",
       " 'GRR': 'GREER, SC',\n",
       " 'MYR': 'MYRTLE BEACH, SC',\n",
       " 'SPF': 'BLACK HILLS, SPEARFISH, SD',\n",
       " 'HON': 'HOWES REGIONAL ARPT - HURON, SD',\n",
       " 'SAI': 'SAIPAN, SPN',\n",
       " 'TYS': 'MC GHEE TYSON - ALCOA, TN',\n",
       " 'MEM': 'MEMPHIS, TN',\n",
       " 'NSV': 'NASHVILLE, TN',\n",
       " 'TRI': 'TRI CITY ARPT, TN',\n",
       " 'ADS': 'ADDISON AIRPORT- ADDISON, TX',\n",
       " 'ADT': 'AMISTAD DAM, TX',\n",
       " 'ANZ': 'ANZALDUAS, TX',\n",
       " 'AUS': 'AUSTIN, TX',\n",
       " 'BEA': 'BEAUMONT, TX',\n",
       " 'BBP': 'BIG BEND PARK, TX (BPS)',\n",
       " 'SCC': 'BP SPEC COORD. CTR, TX',\n",
       " 'BTC': 'BP TACTICAL UNIT, TX',\n",
       " 'BOA': 'BRIDGE OF AMERICAS, TX',\n",
       " 'BRO': 'BROWNSVILLE, TX',\n",
       " 'CRP': 'CORPUS CHRISTI, TX',\n",
       " 'DAL': 'DALLAS, TX',\n",
       " 'DLR': 'DEL RIO, TX',\n",
       " 'DNA': 'DONNA, TX',\n",
       " 'EGP': 'EAGLE PASS, TX',\n",
       " 'ELP': 'EL PASO, TX',\n",
       " 'FAB': 'FABENS, TX',\n",
       " 'FAL': 'FALCON HEIGHTS, TX',\n",
       " 'FTH': 'FORT HANCOCK, TX',\n",
       " 'AFW': 'FORT WORTH ALLIANCE, TX',\n",
       " 'FPT': 'FREEPORT, TX',\n",
       " 'GAL': 'GALVESTON, TX',\n",
       " 'HLG': 'HARLINGEN, TX',\n",
       " 'HID': 'HIDALGO, TX',\n",
       " 'HOU': 'HOUSTON, TX',\n",
       " 'SGR': 'HULL FIELD, SUGAR LAND ARPT, TX',\n",
       " 'LLB': 'JUAREZ-LINCOLN BRIDGE, TX',\n",
       " 'LCB': 'LAREDO COLUMBIA BRIDGE, TX',\n",
       " 'LRN': 'LAREDO NORTH, TX',\n",
       " 'LAR': 'LAREDO, TX',\n",
       " 'LSE': 'LOS EBANOS, TX',\n",
       " 'IND': 'LOS INDIOS, TX',\n",
       " 'LOI': 'LOS INDIOS, TX',\n",
       " 'MRS': 'MARFA, TX (BPS)',\n",
       " 'MCA': 'MCALLEN, TX',\n",
       " 'MAF': 'ODESSA REGIONAL, TX',\n",
       " 'PDN': 'PASO DEL NORTE,TX',\n",
       " 'PBB': 'PEACE BRIDGE, NY',\n",
       " 'PHR': 'PHARR, TX',\n",
       " 'PAR': 'PORT ARTHUR, TX',\n",
       " 'ISB': 'PORT ISABEL, TX',\n",
       " 'POE': 'PORT OF EL PASO, TX',\n",
       " 'PRE': 'PRESIDIO, TX',\n",
       " 'PGR': 'PROGRESO, TX',\n",
       " 'RIO': 'RIO GRANDE CITY, TX',\n",
       " 'ROM': 'ROMA, TX',\n",
       " 'SNA': 'SAN ANTONIO, TX',\n",
       " 'SNN': 'SANDERSON, TX',\n",
       " 'VIB': 'VETERAN INTL BRIDGE, TX',\n",
       " 'YSL': 'YSLETA, TX',\n",
       " 'CHA': 'CHARLOTTE AMALIE, VI',\n",
       " 'CHR': 'CHRISTIANSTED, VI',\n",
       " 'CRU': 'CRUZ BAY, ST JOHN, VI',\n",
       " 'FRK': 'FREDERIKSTED, VI',\n",
       " 'STT': 'ST THOMAS, VI',\n",
       " 'LGU': 'CACHE AIRPORT - LOGAN, UT',\n",
       " 'SLC': 'SALT LAKE CITY, UT',\n",
       " 'CHO': 'ALBEMARLE CHARLOTTESVILLE, VA',\n",
       " 'DAA': 'DAVISON AAF - FAIRFAX CNTY, VA',\n",
       " 'HOP': 'HOPEWELL, VA',\n",
       " 'HEF': 'MANASSAS, VA #ARPT',\n",
       " 'NWN': 'NEWPORT, VA',\n",
       " 'NOR': 'NORFOLK, VA',\n",
       " 'RCM': 'RICHMOND, VA',\n",
       " 'ABS': 'ALBURG SPRINGS, VT',\n",
       " 'ABG': 'ALBURG, VT',\n",
       " 'BEB': 'BEEBE PLAIN, VT',\n",
       " 'BEE': 'BEECHER FALLS, VT',\n",
       " 'BRG': 'BURLINGTON, VT',\n",
       " 'CNA': 'CANAAN, VT',\n",
       " 'DER': 'DERBY LINE, VT (I-91)',\n",
       " 'DLV': 'DERBY LINE, VT (RT. 5)',\n",
       " 'ERC': 'EAST RICHFORD, VT',\n",
       " 'HIG': 'HIGHGATE SPRINGS, VT',\n",
       " 'MOR': 'MORSES LINE, VT',\n",
       " 'NPV': 'NEWPORT, VT',\n",
       " 'NRT': 'NORTH TROY, VT',\n",
       " 'NRN': 'NORTON, VT',\n",
       " 'PIV': 'PINNACLE ROAD, VT',\n",
       " 'RIF': 'RICHFORT, VT',\n",
       " 'STA': 'ST ALBANS, VT',\n",
       " 'SWB': 'SWANTON, VT (BP - SECTOR HQ)',\n",
       " 'WBE': 'WEST BERKSHIRE, VT',\n",
       " 'ABE': 'ABERDEEN, WA',\n",
       " 'ANA': 'ANACORTES, WA',\n",
       " 'BEL': 'BELLINGHAM, WA',\n",
       " 'BLI': 'BELLINGHAM, WASHINGTON #INTL',\n",
       " 'BLA': 'BLAINE, WA',\n",
       " 'BWA': 'BOUNDARY, WA',\n",
       " 'CUR': 'CURLEW, WA (BPS)',\n",
       " 'DVL': 'DANVILLE, WA',\n",
       " 'EVE': 'EVERETT, WA',\n",
       " 'FER': 'FERRY, WA',\n",
       " 'FRI': 'FRIDAY HARBOR, WA',\n",
       " 'FWA': 'FRONTIER, WA',\n",
       " 'KLM': 'KALAMA, WA',\n",
       " 'LAU': 'LAURIER, WA',\n",
       " 'LON': 'LONGVIEW, WA',\n",
       " 'MET': 'METALINE FALLS, WA',\n",
       " 'MWH': 'MOSES LAKE GRANT COUNTY ARPT, WA',\n",
       " 'NEA': 'NEAH BAY, WA',\n",
       " 'NIG': 'NIGHTHAWK, WA',\n",
       " 'OLY': 'OLYMPIA, WA',\n",
       " 'ORO': 'OROVILLE, WA',\n",
       " 'PWB': 'PASCO, WA',\n",
       " 'PIR': 'POINT ROBERTS, WA',\n",
       " 'PNG': 'PORT ANGELES, WA',\n",
       " 'PTO': 'PORT TOWNSEND, WA',\n",
       " 'SEA': 'SEATTLE, WA',\n",
       " 'SPO': 'SPOKANE, WA',\n",
       " 'SUM': 'SUMAS, WA',\n",
       " 'TAC': 'TACOMA, WA',\n",
       " 'PSC': 'TRI-CITIES - PASCO, WA',\n",
       " 'VAN': 'VANCOUVER, WA',\n",
       " 'AGM': 'ALGOMA, WI',\n",
       " 'BAY': 'BAYFIELD, WI',\n",
       " 'GRB': 'GREEN BAY, WI',\n",
       " 'MNW': 'MANITOWOC, WI',\n",
       " 'MIL': 'MILWAUKEE, WI',\n",
       " 'MSN': 'TRUAX FIELD - DANE COUNTY, WI',\n",
       " 'CHS': 'CHARLESTON, WV',\n",
       " 'CLK': 'CLARKSBURG, WV',\n",
       " 'BLF': 'MERCER COUNTY, WV',\n",
       " 'CSP': 'CASPER, WY',\n",
       " 'XXX': 'NOT REPORTED/UNKNOWN',\n",
       " '888': 'UNIDENTIFED AIR / SEAPORT',\n",
       " 'UNK': 'UNKNOWN POE',\n",
       " 'CLG': 'CALGARY, CANADA',\n",
       " 'EDA': 'EDMONTON, CANADA',\n",
       " 'YHC': 'HAKAI PASS, CANADA',\n",
       " 'HAL': 'Halifax, NS, Canada',\n",
       " 'MON': 'MONTREAL, CANADA',\n",
       " 'OTT': 'OTTAWA, CANADA',\n",
       " 'YXE': 'SASKATOON, CANADA',\n",
       " 'TOR': 'TORONTO, CANADA',\n",
       " 'VCV': 'VANCOUVER, CANADA',\n",
       " 'VIC': 'VICTORIA, CANADA',\n",
       " 'WIN': 'WINNIPEG, CANADA',\n",
       " 'AMS': 'AMSTERDAM-SCHIPHOL, NETHERLANDS',\n",
       " 'ARB': 'ARUBA, NETH ANTILLES',\n",
       " 'BAN': 'BANKOK, THAILAND',\n",
       " 'BEI': 'BEICA #ARPT, ETHIOPIA',\n",
       " 'PEK': 'BEIJING CAPITAL INTL, PRC',\n",
       " 'BDA': 'KINDLEY FIELD, BERMUDA',\n",
       " 'BOG': 'BOGOTA, EL DORADO #ARPT, COLOMBIA',\n",
       " 'EZE': 'BUENOS AIRES, MINISTRO PIST, ARGENTINA',\n",
       " 'CUN': 'CANCUN, MEXICO',\n",
       " 'CRQ': 'CARAVELAS, BA #ARPT, BRAZIL',\n",
       " 'MVD': 'CARRASCO, URUGUAY',\n",
       " 'DUB': 'DUBLIN, IRELAND',\n",
       " 'FOU': 'FOUGAMOU #ARPT, GABON',\n",
       " 'FBA': 'FREEPORT, BAHAMAS',\n",
       " 'MTY': 'GEN M. ESCOBEDO, Monterrey, MX',\n",
       " 'HMO': 'GEN PESQUEIRA GARCIA, MX',\n",
       " 'GCM': 'GRAND CAYMAN, CAYMAN ISLAND',\n",
       " 'GDL': 'GUADALAJARA, MIGUEL HIDAL, MX',\n",
       " 'HAM': 'HAMILTON, BERMUDA',\n",
       " 'ICN': 'INCHON, SEOUL KOREA',\n",
       " 'IWA': 'INVALID - IWAKUNI, JAPAN',\n",
       " 'CND': 'KOGALNICEANU, ROMANIA',\n",
       " 'LAH': 'LABUHA ARPT, INDONESIA',\n",
       " 'DUR': 'LOUIS BOTHA, SOUTH AFRICA',\n",
       " 'MAL': 'MANGOLE ARPT, INDONESIA',\n",
       " 'MDE': 'MEDELLIN, COLOMBIA',\n",
       " 'MEX': 'JUAREZ INTL, MEXICO CITY, MX',\n",
       " 'LHR': 'MIDDLESEX, ENGLAND',\n",
       " 'NBO': 'NAIROBI, KENYA',\n",
       " 'NAS': 'NASSAU, BAHAMAS',\n",
       " 'NCA': 'NORTH CAICOS, TURK & CAIMAN',\n",
       " 'PTY': 'OMAR TORRIJOS, PANAMA',\n",
       " 'SPV': 'PAPUA, NEW GUINEA',\n",
       " 'UIO': 'QUITO (MARISCAL SUCR), ECUADOR',\n",
       " 'RIT': 'ROME, ITALY',\n",
       " 'SNO': 'SAKON NAKHON #ARPT, THAILAND',\n",
       " 'SLP': 'SAN LUIS POTOSI #ARPT, MEXICO',\n",
       " 'SAN': 'SAN SALVADOR, EL SALVADOR',\n",
       " 'SRO': 'SANTANA RAMOS #ARPT, COLOMBIA',\n",
       " 'GRU': 'GUARULHOS INTL, SAO PAULO, BRAZIL',\n",
       " 'SHA': 'SHANNON, IRELAND',\n",
       " 'HIL': 'SHILLAVO, ETHIOPIA',\n",
       " 'TOK': 'TOROKINA #ARPT, PAPUA, NEW GUINEA',\n",
       " 'VER': 'VERACRUZ, MEXICO',\n",
       " 'LGW': 'WEST SUSSEX, ENGLAND',\n",
       " 'ZZZ': 'MEXICO Land (Banco de Mexico)',\n",
       " 'CHN': 'No PORT Code (CHN)',\n",
       " 'CNC': 'CANNON CORNERS, NY',\n",
       " 'MAA': 'Abu Dhabi',\n",
       " 'AG0': 'MAGNOLIA, AR',\n",
       " 'BHM': 'BAR HARBOR, ME',\n",
       " 'BHX': 'BIRMINGHAM, AL',\n",
       " 'CAK': 'AKRON, OH',\n",
       " 'FOK': 'SUFFOLK COUNTY, NY',\n",
       " 'LND': 'LANDER, WY',\n",
       " 'MAR': 'MARFA, TX',\n",
       " 'MLI': 'MOLINE, IL',\n",
       " 'RIV': 'RIVERSIDE, CA',\n",
       " 'RME': 'ROME, NY',\n",
       " 'VNY': 'VAN NUYS, CA',\n",
       " 'YUM': 'YUMA, AZ',\n",
       " 'FRG': 'Collapsed (FOK) 06/15',\n",
       " 'HRL': 'Collapsed (HLG) 06/15',\n",
       " 'ISP': 'Collapsed (FOK) 06/15',\n",
       " 'JSJ': 'Collapsed (SAJ) 06/15',\n",
       " 'BUS': 'Collapsed (BUF) 06/15',\n",
       " 'IAG': 'Collapsed (NIA) 06/15',\n",
       " 'PHN': 'Collapsed (PHU) 06/15',\n",
       " 'STN': 'Collapsed (STR) 06/15',\n",
       " 'VMB': 'Collapsed (VNB) 06/15',\n",
       " 'T01': 'Collapsed (SEA) 06/15',\n",
       " 'PHF': 'No PORT Code (PHF)',\n",
       " 'DRV': 'No PORT Code (DRV)',\n",
       " 'FTB': 'No PORT Code (FTB)',\n",
       " 'GAC': 'No PORT Code (GAC)',\n",
       " 'GMT': 'No PORT Code (GMT)',\n",
       " 'JFA': 'No PORT Code (JFA)',\n",
       " 'JMZ': 'No PORT Code (JMZ)',\n",
       " 'NC8': 'No PORT Code (NC8)',\n",
       " 'NYL': 'No PORT Code (NYL)',\n",
       " 'OAI': 'No PORT Code (OAI)',\n",
       " 'PCW': 'No PORT Code (PCW)',\n",
       " 'WA5': 'No PORT Code (WAS)',\n",
       " 'WTR': 'No PORT Code (WTR)',\n",
       " 'X96': 'No PORT Code (X96)',\n",
       " 'XNA': 'No PORT Code (XNA)',\n",
       " 'YGF': 'No PORT Code (YGF)',\n",
       " '5T6': 'No PORT Code (5T6)',\n",
       " '060': 'No PORT Code (60)',\n",
       " 'SP0': 'No PORT Code (SP0)',\n",
       " 'W55': 'No PORT Code (W55)',\n",
       " 'X44': 'No PORT Code (X44)',\n",
       " 'AUH': 'No PORT Code (AUH)',\n",
       " 'RYY': 'No PORT Code (RYY)',\n",
       " 'SUS': 'No PORT Code (SUS)',\n",
       " '74S': 'No PORT Code (74S)',\n",
       " 'ATW': 'No PORT Code (ATW)',\n",
       " 'CPX': 'No PORT Code (CPX)',\n",
       " 'MTH': 'No PORT Code (MTH)',\n",
       " 'PFN': 'No PORT Code (PFN)',\n",
       " 'SCH': 'No PORT Code (SCH)',\n",
       " 'ASI': 'No PORT Code (ASI)',\n",
       " 'BKF': 'No PORT Code (BKF)',\n",
       " 'DAY': 'No PORT Code (DAY)',\n",
       " 'Y62': 'No PORT Code (Y62)',\n",
       " 'AG': 'No PORT Code (AG)',\n",
       " 'BCM': 'No PORT Code (BCM)',\n",
       " 'DEC': 'No PORT Code (DEC)',\n",
       " 'PLB': 'No PORT Code (PLB)',\n",
       " 'CXO': 'No PORT Code (CXO)',\n",
       " 'JBQ': 'No PORT Code (JBQ)',\n",
       " 'JIG': 'No PORT Code (JIG)',\n",
       " 'OGS': 'No PORT Code (OGS)',\n",
       " 'TIW': 'No PORT Code (TIW)',\n",
       " 'OTS': 'No PORT Code (OTS)',\n",
       " 'AMT': 'No PORT Code (AMT)',\n",
       " 'EGE': 'No PORT Code (EGE)',\n",
       " 'GPI': 'No PORT Code (GPI)',\n",
       " 'NGL': 'No PORT Code (NGL)',\n",
       " 'OLM': 'No PORT Code (OLM)',\n",
       " '.GA': 'No PORT Code (.GA)',\n",
       " 'CLX': 'No PORT Code (CLX)',\n",
       " 'CP': 'No PORT Code (CP)',\n",
       " 'FSC': 'No PORT Code (FSC)',\n",
       " 'NK': 'No PORT Code (NK)',\n",
       " 'ADU': 'No PORT Code (ADU)',\n",
       " 'AKT': 'No PORT Code (AKT)',\n",
       " 'LIT': 'No PORT Code (LIT)',\n",
       " 'A2A': 'No PORT Code (A2A)',\n",
       " 'OSN': 'No PORT Code (OSN)'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(cicid=5748517.0, i94yr=2016.0, i94mon=4.0, i94cit=245.0, i94res=438.0, i94port='LOS', arrdate=20574.0, i94mode=1.0, i94addr='CA', depdate=20582.0, i94bir=40.0, i94visa=1.0, count=1.0, dtadfile='20160430', visapost='SYD', occup=None, entdepa='G', entdepd='O', entdepu=None, matflag='M', biryear=1976.0, dtaddto='10292016', gender='F', insnum=None, airline='QF', admnum=94953870030.0, fltno='00011', visatype='B1')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of rows and columns for cities: (2891, 12)\n",
      "count of rows and columns for airports: (55075, 12)\n",
      "count of rows and columns for immigration: (3096313, 28)\n"
     ]
    }
   ],
   "source": [
    "#understand number of rows and columns\n",
    "print(f'count of rows and columns for cities: {c.shape}')\n",
    "print(f'count of rows and columns for airports: {a.shape}')\n",
    "print(f'count of rows and columns for immigration: {immigration.count(), len(immigration.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   City                    2891 non-null   object \n",
      " 1   State                   2891 non-null   object \n",
      " 2   Median Age              2891 non-null   float64\n",
      " 3   Male Population         2888 non-null   float64\n",
      " 4   Female Population       2888 non-null   float64\n",
      " 5   Total Population        2891 non-null   int64  \n",
      " 6   Number of Veterans      2878 non-null   float64\n",
      " 7   Foreign-born            2878 non-null   float64\n",
      " 8   Average Household Size  2875 non-null   float64\n",
      " 9   State Code              2891 non-null   object \n",
      " 10  Race                    2891 non-null   object \n",
      " 11  Count                   2891 non-null   int64  \n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#understand columns and data types\n",
    "c.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ident         55075 non-null  object \n",
      " 1   type          55075 non-null  object \n",
      " 2   name          55075 non-null  object \n",
      " 3   elevation_ft  48069 non-null  float64\n",
      " 4   continent     27356 non-null  object \n",
      " 5   iso_country   54828 non-null  object \n",
      " 6   iso_region    55075 non-null  object \n",
      " 7   municipality  49399 non-null  object \n",
      " 8   gps_code      41030 non-null  object \n",
      " 9   iata_code     9189 non-null   object \n",
      " 10  local_code    28686 non-null  object \n",
      " 11  coordinates   55075 non-null  object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  1000 non-null   int64  \n",
      " 1   cicid       1000 non-null   float64\n",
      " 2   i94yr       1000 non-null   float64\n",
      " 3   i94mon      1000 non-null   float64\n",
      " 4   i94cit      1000 non-null   float64\n",
      " 5   i94res      1000 non-null   float64\n",
      " 6   i94port     1000 non-null   object \n",
      " 7   arrdate     1000 non-null   float64\n",
      " 8   i94mode     1000 non-null   float64\n",
      " 9   i94addr     941 non-null    object \n",
      " 10  depdate     951 non-null    float64\n",
      " 11  i94bir      1000 non-null   float64\n",
      " 12  i94visa     1000 non-null   float64\n",
      " 13  count       1000 non-null   float64\n",
      " 14  dtadfile    1000 non-null   int64  \n",
      " 15  visapost    382 non-null    object \n",
      " 16  occup       4 non-null      object \n",
      " 17  entdepa     1000 non-null   object \n",
      " 18  entdepd     954 non-null    object \n",
      " 19  entdepu     0 non-null      float64\n",
      " 20  matflag     954 non-null    object \n",
      " 21  biryear     1000 non-null   float64\n",
      " 22  dtaddto     1000 non-null   object \n",
      " 23  gender      859 non-null    object \n",
      " 24  insnum      35 non-null     float64\n",
      " 25  airline     967 non-null    object \n",
      " 26  admnum      1000 non-null   float64\n",
      " 27  fltno       992 non-null    object \n",
      " 28  visatype    1000 non-null   object \n",
      "dtypes: float64(15), int64(2), object(12)\n",
      "memory usage: 226.7+ KB\n"
     ]
    }
   ],
   "source": [
    "i.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{int64: ['Total Population', 'Count'], float64: ['Median Age', 'Male Population', 'Female Population', 'Number of Veterans', 'Foreign-born', 'Average Household Size'], object: ['City', 'State', 'State Code', 'Race']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.columns.to_series().groupby(c.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2891.000000</td>\n",
       "      <td>2.888000e+03</td>\n",
       "      <td>2.888000e+03</td>\n",
       "      <td>2.891000e+03</td>\n",
       "      <td>2878.000000</td>\n",
       "      <td>2.878000e+03</td>\n",
       "      <td>2875.000000</td>\n",
       "      <td>2.891000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.494881</td>\n",
       "      <td>9.732843e+04</td>\n",
       "      <td>1.017696e+05</td>\n",
       "      <td>1.989668e+05</td>\n",
       "      <td>9367.832523</td>\n",
       "      <td>4.065360e+04</td>\n",
       "      <td>2.742543</td>\n",
       "      <td>4.896377e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.401617</td>\n",
       "      <td>2.162999e+05</td>\n",
       "      <td>2.315646e+05</td>\n",
       "      <td>4.475559e+05</td>\n",
       "      <td>13211.219924</td>\n",
       "      <td>1.557491e+05</td>\n",
       "      <td>0.433291</td>\n",
       "      <td>1.443856e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.900000</td>\n",
       "      <td>2.928100e+04</td>\n",
       "      <td>2.734800e+04</td>\n",
       "      <td>6.321500e+04</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>8.610000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.800000</td>\n",
       "      <td>3.928900e+04</td>\n",
       "      <td>4.122700e+04</td>\n",
       "      <td>8.042900e+04</td>\n",
       "      <td>3739.000000</td>\n",
       "      <td>9.224000e+03</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>3.435000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.300000</td>\n",
       "      <td>5.234100e+04</td>\n",
       "      <td>5.380900e+04</td>\n",
       "      <td>1.067820e+05</td>\n",
       "      <td>5397.000000</td>\n",
       "      <td>1.882200e+04</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>1.378000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>8.664175e+04</td>\n",
       "      <td>8.960400e+04</td>\n",
       "      <td>1.752320e+05</td>\n",
       "      <td>9368.000000</td>\n",
       "      <td>3.397175e+04</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>5.444700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.500000</td>\n",
       "      <td>4.081698e+06</td>\n",
       "      <td>4.468707e+06</td>\n",
       "      <td>8.550405e+06</td>\n",
       "      <td>156961.000000</td>\n",
       "      <td>3.212500e+06</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>3.835726e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Median Age  Male Population  Female Population  Total Population  Number of Veterans  Foreign-born  Average Household Size         Count\n",
       "count  2891.000000     2.888000e+03       2.888000e+03      2.891000e+03         2878.000000  2.878000e+03             2875.000000  2.891000e+03\n",
       "mean     35.494881     9.732843e+04       1.017696e+05      1.989668e+05         9367.832523  4.065360e+04                2.742543  4.896377e+04\n",
       "std       4.401617     2.162999e+05       2.315646e+05      4.475559e+05        13211.219924  1.557491e+05                0.433291  1.443856e+05\n",
       "min      22.900000     2.928100e+04       2.734800e+04      6.321500e+04          416.000000  8.610000e+02                2.000000  9.800000e+01\n",
       "25%      32.800000     3.928900e+04       4.122700e+04      8.042900e+04         3739.000000  9.224000e+03                2.430000  3.435000e+03\n",
       "50%      35.300000     5.234100e+04       5.380900e+04      1.067820e+05         5397.000000  1.882200e+04                2.650000  1.378000e+04\n",
       "75%      38.000000     8.664175e+04       8.960400e+04      1.752320e+05         9368.000000  3.397175e+04                2.950000  5.444700e+04\n",
       "max      70.500000     4.081698e+06       4.468707e+06      8.550405e+06       156961.000000  3.212500e+06                4.980000  3.835726e+06"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values in Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_data(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "        df - (dataframe), dataframe to check for missing values in its columns\n",
    "    OUTPUT:\n",
    "        df_null: (dataframe), with count & percentage of missing values in input dataframe columns\n",
    "    '''\n",
    "    null_data = df.isnull().sum()[df.isnull().sum() > 0]\n",
    "    \n",
    "    data_dict = {'count': null_data.values, \n",
    "                 'pct': np.round(null_data.values *100/df.shape[0],2)}\n",
    "    \n",
    "    df_null = pd.DataFrame(data=data_dict, index=null_data.index)\n",
    "    df_null.sort_values(by='count', ascending=False, inplace=True)\n",
    "    return df_null\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.isnull().sum().sum() #count of all missing values in Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average Household Size</th>\n",
       "      <td>16</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Veterans</th>\n",
       "      <td>13</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foreign-born</th>\n",
       "      <td>13</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male Population</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female Population</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count   pct\n",
       "Average Household Size     16  0.55\n",
       "Number of Veterans         13  0.45\n",
       "Foreign-born               13  0.45\n",
       "Male Population             3  0.10\n",
       "Female Population           3  0.10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_missing_data(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>San Juan</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>41.4</td>\n",
       "      <td>155408.0</td>\n",
       "      <td>186829.0</td>\n",
       "      <td>342237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>335559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Caguas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>40.4</td>\n",
       "      <td>34743.0</td>\n",
       "      <td>42265.0</td>\n",
       "      <td>77008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>76349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Bayamón</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>39.4</td>\n",
       "      <td>80128.0</td>\n",
       "      <td>90131.0</td>\n",
       "      <td>170259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>169155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231.0</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>72211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>San Juan</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>41.4</td>\n",
       "      <td>155408.0</td>\n",
       "      <td>186829.0</td>\n",
       "      <td>342237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>4031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231.0</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FL</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>Guaynabo</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>42.2</td>\n",
       "      <td>33066.0</td>\n",
       "      <td>37426.0</td>\n",
       "      <td>70492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>Mayagüez</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>38.1</td>\n",
       "      <td>30799.0</td>\n",
       "      <td>35782.0</td>\n",
       "      <td>66581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Asian</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>Mayagüez</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>38.1</td>\n",
       "      <td>30799.0</td>\n",
       "      <td>35782.0</td>\n",
       "      <td>66581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>65521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>Caguas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>40.4</td>\n",
       "      <td>34743.0</td>\n",
       "      <td>42265.0</td>\n",
       "      <td>77008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231.0</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>San Juan</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>41.4</td>\n",
       "      <td>155408.0</td>\n",
       "      <td>186829.0</td>\n",
       "      <td>342237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>Carolina</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>42.0</td>\n",
       "      <td>64758.0</td>\n",
       "      <td>77308.0</td>\n",
       "      <td>142066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>139967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>Carolina</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>42.0</td>\n",
       "      <td>64758.0</td>\n",
       "      <td>77308.0</td>\n",
       "      <td>142066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>12143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>Guaynabo</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>42.2</td>\n",
       "      <td>33066.0</td>\n",
       "      <td>37426.0</td>\n",
       "      <td>70492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>69936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>40.5</td>\n",
       "      <td>56968.0</td>\n",
       "      <td>64615.0</td>\n",
       "      <td>121583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>120705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City        State  Median Age  Male Population  Female Population  Total Population  Number of Veterans  Foreign-born  Average Household Size State Code                               Race   Count\n",
       "5         San Juan  Puerto Rico        41.4         155408.0           186829.0            342237                 NaN           NaN                     NaN         PR                 Hispanic or Latino  335559\n",
       "9           Caguas  Puerto Rico        40.4          34743.0            42265.0             77008                 NaN           NaN                     NaN         PR                 Hispanic or Latino   76349\n",
       "280        Bayamón  Puerto Rico        39.4          80128.0            90131.0            170259                 NaN           NaN                     NaN         PR                 Hispanic or Latino  169155\n",
       "740   The Villages      Florida        70.5              NaN                NaN             72590             15231.0        4034.0                     NaN         FL                              White   72211\n",
       "806       San Juan  Puerto Rico        41.4         155408.0           186829.0            342237                 NaN           NaN                     NaN         PR  American Indian and Alaska Native    4031\n",
       "908   The Villages      Florida        70.5              NaN                NaN             72590             15231.0        4034.0                     NaN         FL          Black or African-American     331\n",
       "1121      Guaynabo  Puerto Rico        42.2          33066.0            37426.0             70492                 NaN           NaN                     NaN         PR  American Indian and Alaska Native     589\n",
       "1196      Mayagüez  Puerto Rico        38.1          30799.0            35782.0             66581                 NaN           NaN                     NaN         PR                              Asian     235\n",
       "1443      Mayagüez  Puerto Rico        38.1          30799.0            35782.0             66581                 NaN           NaN                     NaN         PR                 Hispanic or Latino   65521\n",
       "1530        Caguas  Puerto Rico        40.4          34743.0            42265.0             77008                 NaN           NaN                     NaN         PR  American Indian and Alaska Native     624\n",
       "1547  The Villages      Florida        70.5              NaN                NaN             72590             15231.0        4034.0                     NaN         FL                 Hispanic or Latino    1066\n",
       "1826      San Juan  Puerto Rico        41.4         155408.0           186829.0            342237                 NaN           NaN                     NaN         PR                              Asian    2452\n",
       "2079      Carolina  Puerto Rico        42.0          64758.0            77308.0            142066                 NaN           NaN                     NaN         PR                 Hispanic or Latino  139967\n",
       "2284      Carolina  Puerto Rico        42.0          64758.0            77308.0            142066                 NaN           NaN                     NaN         PR  American Indian and Alaska Native   12143\n",
       "2558      Guaynabo  Puerto Rico        42.2          33066.0            37426.0             70492                 NaN           NaN                     NaN         PR                 Hispanic or Latino   69936\n",
       "2646         Ponce  Puerto Rico        40.5          56968.0            64615.0            121583                 NaN           NaN                     NaN         PR                 Hispanic or Latino  120705"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nans(df): \n",
    "    return df[df.isnull().any(axis=1)]\n",
    "\n",
    "nans(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing values comprise less than 1% of Cities data, so it's safe to drop them\n",
    "c2 = c.dropna(axis=0)\n",
    "c2.isnull().sum().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values in Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126968"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.isnull().sum().sum() #count of all missing values in Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iata_code</th>\n",
       "      <td>45886</td>\n",
       "      <td>83.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continent</th>\n",
       "      <td>27719</td>\n",
       "      <td>50.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_code</th>\n",
       "      <td>26389</td>\n",
       "      <td>47.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gps_code</th>\n",
       "      <td>14045</td>\n",
       "      <td>25.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevation_ft</th>\n",
       "      <td>7006</td>\n",
       "      <td>12.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>municipality</th>\n",
       "      <td>5676</td>\n",
       "      <td>10.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iso_country</th>\n",
       "      <td>247</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    pct\n",
       "iata_code     45886  83.32\n",
       "continent     27719  50.33\n",
       "local_code    26389  47.91\n",
       "gps_code      14045  25.50\n",
       "elevation_ft   7006  12.72\n",
       "municipality   5676  10.31\n",
       "iso_country     247   0.45"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_missing_data(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                  name  elevation_ft iso_country iso_region municipality                         coordinates\n",
       "0   00A       heliport     Total Rf Heliport          11.0          US      US-PA     Bensalem  -74.93360137939453, 40.07080078125\n",
       "1  00AA  small_airport  Aero B Ranch Airport        3435.0          US      US-KS        Leoti              -101.473911, 38.704022"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping columns that are missing over 25% of data\n",
    "cols = a.columns[a.isnull().sum()/len(a) > .25]\n",
    "a2 = a.drop(cols,axis=1)\n",
    "a2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping the remaining rows with null values\n",
    "a2.dropna(axis=0, inplace=True)\n",
    "a2.isnull().sum().sum() #count of all missing values in Airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values in Immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(immigration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cicid': 0.0,\n",
       " 'i94yr': 0.0,\n",
       " 'i94mon': 0.0,\n",
       " 'i94cit': 0.0,\n",
       " 'i94res': 0.0,\n",
       " 'i94port': 0.0,\n",
       " 'arrdate': 0.0,\n",
       " 'i94mode': 7.729379857947582e-05,\n",
       " 'i94addr': 0.04910743449916529,\n",
       " 'depdate': 0.045907341875969,\n",
       " 'i94bir': 0.0002590474169964859,\n",
       " 'i94visa': 0.0,\n",
       " 'count': 0.0,\n",
       " 'dtadfile': 3.2340501497688625e-07,\n",
       " 'visapost': 0.6080088664718906,\n",
       " 'occup': 0.9973755683034625,\n",
       " 'entdepa': 7.697039356449892e-05,\n",
       " 'entdepd': 0.0446046664756421,\n",
       " 'entdepu': 0.999873548639144,\n",
       " 'matflag': 0.0446046664756421,\n",
       " 'biryear': 0.0002590474169964859,\n",
       " 'dtaddto': 0.00015426419214397473,\n",
       " 'gender': 0.13397279128927997,\n",
       " 'insnum': 0.9632262625570083,\n",
       " 'airline': 0.027045391187472068,\n",
       " 'admnum': 0.0,\n",
       " 'fltno': 0.0063222446377831495,\n",
       " 'visatype': 0.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2 = immigration[~immigration[\"i94port\"].isin(missing_ports_list)] #filtering out missng ports derived from the SAS file\n",
    "\n",
    "{col:i2.filter(i2[col].isNull()).count() / i2.count() for col in i2.columns} #checking % of null values in each col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cicid': 0.0,\n",
       " 'i94yr': 0.0,\n",
       " 'i94mon': 0.0,\n",
       " 'i94cit': 0.0,\n",
       " 'i94res': 0.0,\n",
       " 'i94port': 0.0,\n",
       " 'arrdate': 0.0,\n",
       " 'i94mode': 0.0,\n",
       " 'i94addr': 0.0,\n",
       " 'depdate': 0.0,\n",
       " 'i94bir': 0.0,\n",
       " 'i94visa': 0.0,\n",
       " 'count': 0.0,\n",
       " 'dtadfile': 0.0,\n",
       " 'entdepa': 0.0,\n",
       " 'entdepd': 0.0,\n",
       " 'matflag': 0.0,\n",
       " 'biryear': 0.0,\n",
       " 'dtaddto': 0.0,\n",
       " 'gender': 0.0,\n",
       " 'airline': 0.0,\n",
       " 'admnum': 0.0,\n",
       " 'fltno': 0.0,\n",
       " 'visatype': 0.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2 = i2.drop(\"insnum\", \"entdepu\", \"occup\", \"visapost\") #dropping extra columns\n",
    "i2 = i2.dropna(how='any') #dropping null values\n",
    "{col:i2.filter(i2[col].isNull()).count() / i2.count() for col in i2.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create udf to convert SAS date to PySpark date \n",
    "@udf(StringType())\n",
    "def convert_datetime(x):\n",
    "    if x:\n",
    "        return (datetime(1960, 1, 1).date() + timedelta(x)).isoformat()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1423.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 717.0 failed 1 times, most recent failure: Lost task 3.0 in stage 717.0 (TID 1196) (192.168.1.14 executor driver): org.apache.spark.SparkException: \nError from python worker:\n  dyld[24154]: dyld cache '/System/Library/dyld/dyld_shared_cache_x86_64h' not loaded: syscall to map cache into shared region failed\n  dyld[24154]: Library not loaded: /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation\n    Referenced from: /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python\n    Reason: tried: '/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation' (no such file), '/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation' (no such file)\nPYTHONPATH was:\n  /Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip:/Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/python/lib/py4j-0.10.9.3-src.zip:/Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/jars/spark-core_2.12-3.2.1.jar\norg.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout and terminated with code: 134.\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:227)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:133)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:106)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:121)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:162)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:130)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.SparkException: \nError from python worker:\n  dyld[24154]: dyld cache '/System/Library/dyld/dyld_shared_cache_x86_64h' not loaded: syscall to map cache into shared region failed\n  dyld[24154]: Library not loaded: /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation\n    Referenced from: /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python\n    Reason: tried: '/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation' (no such file), '/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation' (no such file)\nPYTHONPATH was:\n  /Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip:/Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/python/lib/py4j-0.10.9.3-src.zip:/Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/jars/spark-core_2.12-3.2.1.jar\norg.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout and terminated with code: 134.\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:227)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:133)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:106)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:121)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:162)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:130)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-d14e3a09e74c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                        \"count\").drop_duplicates()\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mi3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \"\"\"\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m             \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \"\"\"\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \"\"\"\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1423.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 717.0 failed 1 times, most recent failure: Lost task 3.0 in stage 717.0 (TID 1196) (192.168.1.14 executor driver): org.apache.spark.SparkException: \nError from python worker:\n  dyld[24154]: dyld cache '/System/Library/dyld/dyld_shared_cache_x86_64h' not loaded: syscall to map cache into shared region failed\n  dyld[24154]: Library not loaded: /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation\n    Referenced from: /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python\n    Reason: tried: '/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation' (no such file), '/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation' (no such file)\nPYTHONPATH was:\n  /Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip:/Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/python/lib/py4j-0.10.9.3-src.zip:/Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/jars/spark-core_2.12-3.2.1.jar\norg.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout and terminated with code: 134.\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:227)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:133)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:106)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:121)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:162)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:130)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.SparkException: \nError from python worker:\n  dyld[24154]: dyld cache '/System/Library/dyld/dyld_shared_cache_x86_64h' not loaded: syscall to map cache into shared region failed\n  dyld[24154]: Library not loaded: /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation\n    Referenced from: /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python\n    Reason: tried: '/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation' (no such file), '/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation' (no such file)\nPYTHONPATH was:\n  /Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip:/Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/python/lib/py4j-0.10.9.3-src.zip:/Users/tatianatikhonova/opt/anaconda3/lib/python3.8/site-packages/pyspark/jars/spark-core_2.12-3.2.1.jar\norg.apache.spark.SparkException: EOFException occurred while reading the port number from pyspark.daemon's stdout and terminated with code: 134.\n\tat org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:227)\n\tat org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:133)\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:106)\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:121)\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:162)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.$anonfun$doExecute$2(EvalPythonExec.scala:130)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "i2 = i2.withColumn(\"arrdate\", convert_datetime(i2.arrdate)) #converting arrival_date of SAS format to PySpark format\n",
    "i2 = i2.filter(i2.i94addr != 'other')\n",
    "\n",
    "i3 = i2.select(col(\"cicid\").alias(\"id\"), \n",
    "                                       col(\"arrdate\").alias(\"arrival_date\"),\n",
    "                                       col(\"i94port\").alias(\"port_code\"),\n",
    "                                       col(\"i94addr\").alias(\"state_code\"),\n",
    "                                       col(\"i94bir\").alias(\"age\"),\n",
    "                                       col(\"gender\").alias(\"gender\"),\n",
    "                                       col(\"i94visa\").alias(\"visa_type\"),\n",
    "                                       \"count\").drop_duplicates()\n",
    "\n",
    "i3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immigration = FACT\n",
    "Airports = DIM\n",
    "Cities = DIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immigration columns:\n",
    "\n",
    "*  cicid      primary key, id from sas file\n",
    "*  i94yr      entry year, 4 digit year\n",
    "*  i94mon     entry month, numeric month\n",
    "*  i94cit     i94 citizenship country code as per SAS Labels Descriptions file\n",
    "*   i94res    i94 residence country code as per SAS Labels Descriptions file\n",
    "*  i94port     i94port code as per SAS Labels Descriptions file\n",
    "*  arrdate     date of arrival in U.S.\n",
    "*  i94mode     code for travel mode of arrival as per SAS Labels Descriptions file\n",
    "*  i94addr     address\n",
    "*  depdate     departure date from U.S.\n",
    "*  i94bir      age of the immigrant\n",
    "*  i94visa     visa category code as per SAS Labels Descriptions file\n",
    "*  dtadfile    Character Date Field - Date added to I-94 Files - CIC does not use */  \n",
    "*  visapost    visa category code as per SAS Labels Descriptions file\n",
    "*  occup       occupation of immigrant\n",
    "*  entdepa     Arrival Flag - admitted or paroled into the U.S. - CIC does not use\n",
    "*  entdepd     Departure Flag - Departed, lost I-94 or is deceased - CIC does not use\n",
    "*  entdepu     Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use\n",
    "*  matflag     Match flag - Match of arrival and departure records\n",
    "*  biryear     birth year of immigrant\n",
    "* count        used for summary stats\n",
    "*  dtaddto     character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use */\n",
    "*  gender      gender of immigrant\n",
    "*  insnum      INS number\n",
    "*  airline     airline code used to arrive in U.S.\n",
    "*  admnum      admission number\n",
    "*  fltno       flight number\n",
    "*  visatype  visa type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-77-33effe78f7ae>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-77-33effe78f7ae>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    fact_immigraions:\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "fact_immigraions:\n",
    "|-- cicid: id from sas file\n",
    "|-- entry_year: 4 digit year\n",
    "|-- entry_month: numeric month\n",
    "|-- origin_country_code: i94 country code as per SAS Labels Descriptions file\n",
    "|-- port_code: i94port code as per SAS Labels Descriptions file\n",
    "|-- arrival_date: date of arrival in U.S.\n",
    "|-- travel_mode_code: code for travel mode of arrival as per SAS Labels Descriptions file\n",
    "|-- us_state_code: two letter U.S. state code\n",
    "|-- departure_date: departure date from U.S.\n",
    "|-- age: age of the immigrant\n",
    "|-- visa_category_code: visa category code as per SAS Labels Descriptions file\n",
    "|-- occupation: occupation of immigrant\n",
    "|-- gender: gender of immigrant\n",
    "|-- birth_year: birth year of immigrant\n",
    "|-- entry_date: Date to which admitted to U.S. (allowed to stay until)\n",
    "|-- airline: airline code used to arrive in U.S.\n",
    "|-- admission_number: admission number\n",
    "|-- flight_number: flight number\n",
    "|-- visa_type: visa type\n",
    "    \n",
    "dim_city_demographics:\n",
    "|-- port_code: i94port code\n",
    "|-- city: U.S. city name\n",
    "|-- state_code: two letter U.S. sate code\n",
    "|-- male_population: total male population\n",
    "|-- female_population: total female population\n",
    "|-- total_population: total population\n",
    "|-- number_of_veterans: number of veterans\n",
    "|-- num_foreign_born: number of foreign born "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
